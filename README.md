# AI агент на LangGraph

Агент на Python строит динамическую цепочку обработки пользовательского запроса: определяет интенты через LLM, собирает маршрут `search -> summarize -> sentiment` либо уходит в `fallback`, обрабатывает шаги и возвращает итоговый ответ. Поддержан быстрый и глубокий режим поиска.

## Архитектура
- Состояние (`agent/models.py`): `user_query`, `detected_intents`, `intermediate_result`, `final_answer`, `next_intent_index`, `search_mode`.
- Граф (`agent/graph.py`): узлы `intent_recognition -> router -> {search|summarize|sentiment|fallback} -> ... -> finalize`. Маршрутизация по списку интентов; завершение в `finalize`.
- Ноды (`agent/handlers.py`): интенты, поиск, суммаризация, тональность, fallback; все ноды обновляют общее состояние и сдвигают `next_intent_index`.
- Цепочки (`agent/chains.py`): промпты + LLM с structured output для интентов и псевдо-поиска.
- CLI (`agent/cli.py`): цикл `input -> graph.invoke -> print`; новое состояние на каждый запрос с `search_mode="deep"`.
- Отказоустойчивость LLM: на каждую ноду задан приоритезированный список моделей; при ошибке текущей берётся следующая (`agent/config.py`, `iter_llms_for_node`).

## LLM и конфигурация
- Три провайдера (OpenAI-совместимые API): Groq, OpenRouter, Cloud.ru. У каждого свой ключ и базовый URL.
- Конфигурация моделей и сэмплинга — в `llm_config.yaml`: списки моделей и параметров на ноды (`intent`, `search`, `summarize`, `sentiment`, `fallback`); перебор до успешной.
- Параметры на модель: `temperature`, `top_p`, `max_tokens`, а также `base_url` и `api_key_env` для выбора провайдера.
- Дефолтный набор (8–12B + лёгкие фолбэки): `ai-sage/GigaChat3-10B-A1.8B` (Cloud.ru), `llama-3.1-8b-instant` (Groq), `google/gemma-3-12b-it:free`, `google/gemma-3-4b-it:free`, `qwen/qwen3-4b:free`, `mistralai/mistral-7b-instruct:free`, `meta-llama/llama-3.2-3b-instruct:free` (OpenRouter).
- Путь к кастомному конфигу можно задать через `LLM_CONFIG_PATH`.

### Почему такие модели
- `ai-sage/GigaChat3-10B-A1.8B` — первый приоритет: сильный русский, structured output/FC, размер в целевом диапазоне.
- `google/gemma-3-12b-it:free` — крепкая классификация и связные ответы в среднем размере.
- `llama-3.1-8b-instant` — быстрый дешёвый фолбэк (Groq).
- `mistralai/mistral-7b-instruct:free`, `qwen/qwen3-4b:free` — диверсификация вендоров через OpenRouter.
- `google/gemma-3-4b-it:free`, `meta-llama/llama-3.2-3b-instruct:free` — лёгкие запасные варианты.
- При недоступности/ошибке текущей модели система автоматически переключается на следующую.

## Переменные окружения
- `GROQ_API_KEY`, `GROQ_BASE_URL` — ключ и базовый URL Groq.  
- `OPENROUTER_API_KEY`, `OPENROUTER_BASE_URL` — ключ и базовый URL OpenRouter.  
- `CLOUDRU_API_KEY`, `CLOUDRU_BASE_URL` — ключ и базовый URL Cloud.ru (GigaChat).  
- `LLM_CONFIG_PATH` — путь к yaml-конфигу моделей (по умолчанию `llm_config.yaml`).  

## Запуск
1) Установите зависимости: `pip install -r requirements.txt`  
2) Скопируйте `.env.example` в `.env`, заполните ключи (`GROQ_API_KEY`, `OPENROUTER_API_KEY`, `CLOUDRU_API_KEY`) и при необходимости их `*_BASE_URL`, отредактируйте `llm_config.yaml`, если нужен другой набор моделей/параметров.  
3) Запустите: `python main.py`  
4) Примеры ввода:  
   - `Найди последние новости о возобновляемой энергетике и кратко перескажи`  
   - `Найди статьи про Москвариум и оцени их тональность`  
   - `Перескажи текст: "В отчете говорится, что рынок вырос на 12% за квартал"`  
   - `Сравни тональность двух отзывов: "понравилось" и "ужасно"`  
   - `Что такое градиентный бустинг?` (уйдет в fallback)  
   - `Найди новости о ядерной энергетике, потом сделай краткий пересказ и оцени тональность`

## Соответствие ТЗ
- Интенты через LLM, поддержка множественных: `IntentPrediction` + нормализация в `intent_recognition_node`.
- Динамический граф LangGraph, порядок интентов учитывается; `search` перед `summarize`.
- Обработчики — отдельные ноды, обновляют общее состояние и итоговый ответ; `fallback` для `none`.
- Состояние на Pydantic с полями из ТЗ.
- Поток: `intent_recognition` -> динамические обработчики -> `finalize`.
- CLI-цикл, многократные запросы, состояние сбрасывается.
- Обработка ошибок: ленивый init LLM, фолбэки в поиске и интентах, логирование.

## Результаты тестов
В ходе ручных прогонов лучшей показала себя `ai-sage/GigaChat3-10B-A1.8B`: уверенно держит русский, даёт структурированный вывод и минимально шумные сниппеты среди 8–12B альтернатив.

Наблюдения по качеству моделей:
- `ai-sage/GigaChat3-10B-A1.8B`: лучшие ответы на русском, стабильный structured output/FC, меньше шумных или англоязычных вставок.
- OpenRouter 8–12B (`gemma-3-12b/4b`, `mistral-7b`, `qwen3-4b`): чаще смешивают рус/англ, больше «мусорных» сниппетов и повторов; требуется больше пост-обработки.
- `llama-3.1-8b-instant` (Groq): самый быстрый, но чаще даёт усечённые/общие формулировки и меньше фактических деталей.

Примеры работы агента:

- `Найди последние новости о подкастах на русском и кратко перескажи`

1. Подкаст «НИИ Понятно» стал популярным, его выпуски собрали два миллиона просмотров.
2. В подкасте «Соц. навигатор» обсуждаются вопросы науки и промышленности, включая уникальные объекты и научные исследования.
3. Подкаст «Обогнавшие время» рассказывает о различных аспектах российской истории, включая архитектуру, искусство и научные достижения.
4. В подкасте «История русского флота» рассматриваются события и личности, связанные с историей российского флота, включая морские сражения и важные морские экспедиции.
5. В подкасте «Гении русских побед» обсуждаются ключевые фигуры и события, связанные с победами советского союза в Великой Отечественной войне и других исторических периодах. 

- `Найди исследования про влияние кофеина на сон и определи тональность выводов`

Тональность:
Тональность текста: позитивная.

Обоснование: В исследованиях подчеркивается, что кофе делает сон более глубоким, что может компенсировать сокращение его общей продолжительности, что воспринимается как положительный эффект.

- `Сравни тональность отзывов: "Сервис отличный" и "Поддержка не отвечает неделями"`

Анализ тональности:
Сервис отличный: позитив (прямое утверждение о положительном опыте).
Поддержка не отвечает неделями: негатив (указание на проблему и неудовлетворенность).

- `Найди лучшие практики A/B-тестирования и перескажи в 3-4 тезисах`

Суммаризация:
1. A/B-тестирование позволяет сравнивать две версии одного элемента, чтобы определить, какая из них эффективнее повышает конверсию.
2. Для проведения A/B-тестирования необходимо сформулировать гипотезу, создать варианты, запустить тест и проанализировать результаты.
3. Использование специализированных инструментов и статистических методов помогает обеспечить точность и достоверность результатов A/B-тестирования.
4. A/B-тестирование применяется для оптимизации различных элементов веб-страниц и рекламных материалов, включая заголовки, кнопки призыва к действию, цвета и другие переменные. 

- `Что такое гребень Реджи?` (fallback для неочевидного запроса)

Ответ:
Гребень Реджи — это гребешок для укладки волос, который помогает создать объем и текстуру прически. Он имеет зубья разной длины и ширины, что позволяет легко расчесывать и укладывать волосы.

- `Определи тональность обзора: "Игра выглядит красиво, но управление хромает"`

Анализ тональности:
нейтрально: визуал хвалят, но управление критикуют; оценки уравновешены.